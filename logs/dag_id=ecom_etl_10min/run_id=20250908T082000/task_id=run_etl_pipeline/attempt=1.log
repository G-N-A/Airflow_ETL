[2025-09-08T14:00:03.030+0530] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-09-08T14:00:03.042+0530] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecom_etl_10min.run_etl_pipeline scheduled__2025-09-08T08:20:00+00:00 [queued]>
[2025-09-08T14:00:03.045+0530] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecom_etl_10min.run_etl_pipeline scheduled__2025-09-08T08:20:00+00:00 [queued]>
[2025-09-08T14:00:03.045+0530] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-09-08T14:00:03.103+0530] {taskinstance.py:2330} INFO - Executing <Task(BashOperator): run_etl_pipeline> on 2025-09-08 08:20:00+00:00
[2025-09-08T14:00:03.111+0530] {standard_task_runner.py:64} INFO - Started process 724331 to run task
[2025-09-08T14:00:03.117+0530] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecom_etl_10min', 'run_etl_pipeline', 'scheduled__2025-09-08T08:20:00+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/ecom_schedules.py', '--cfg-path', '/tmp/tmpbboaox98']
[2025-09-08T14:00:03.121+0530] {standard_task_runner.py:91} INFO - Job 37: Subtask run_etl_pipeline
[2025-09-08T14:00:03.190+0530] {task_command.py:426} INFO - Running <TaskInstance: ecom_etl_10min.run_etl_pipeline scheduled__2025-09-08T08:20:00+00:00 [running]> on host softsuave-ASUS-EXPERTCENTER-D700ME-D500ME
[2025-09-08T14:00:03.332+0530] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecom_etl_10min' AIRFLOW_CTX_TASK_ID='run_etl_pipeline' AIRFLOW_CTX_EXECUTION_DATE='2025-09-08T08:20:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-09-08T08:20:00+00:00'
[2025-09-08T14:00:03.334+0530] {taskinstance.py:430} INFO - ::endgroup::
[2025-09-08T14:00:03.334+0530] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-09-08T14:00:03.335+0530] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', 'bash /media/softsuave/DATA-HDD/DataEngineering/Apache_Airflow/scripts/etl/run_etl.sh | cat']
[2025-09-08T14:00:03.343+0530] {subprocess.py:86} INFO - Output:
[2025-09-08T14:00:03.356+0530] {subprocess.py:93} INFO - [2025-09-08 14:00:03] ðŸš€ Starting E-Commerce ETL Pipeline...
[2025-09-08T14:00:03.356+0530] {subprocess.py:93} INFO - ----------------------------------------
[2025-09-08T14:00:03.357+0530] {subprocess.py:93} INFO -  Source DB   : ecom_db
[2025-09-08T14:00:03.357+0530] {subprocess.py:93} INFO -  Target DB   : ecom_dwh
[2025-09-08T14:00:03.358+0530] {subprocess.py:93} INFO -  Server      : localhost:1433
[2025-09-08T14:00:03.358+0530] {subprocess.py:93} INFO -  Spark Master: local[*]
[2025-09-08T14:00:03.358+0530] {subprocess.py:93} INFO - ----------------------------------------
[2025-09-08T14:00:03.359+0530] {subprocess.py:93} INFO - 
[2025-09-08T14:00:03.359+0530] {subprocess.py:93} INFO - [2025-09-08 14:00:03] ðŸ”„ Running ETL Pipeline with spark-submit...
[2025-09-08T14:00:07.281+0530] {subprocess.py:93} INFO - 25/09/08 14:00:07 WARN Utils: Your hostname, softsuave-ASUS-EXPERTCENTER-D700ME-D500ME resolves to a loopback address: 127.0.1.1; using 192.168.6.3 instead (on interface eno2)
[2025-09-08T14:00:07.282+0530] {subprocess.py:93} INFO - 25/09/08 14:00:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2025-09-08T14:00:11.275+0530] {subprocess.py:93} INFO - 25/09/08 14:00:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-09-08T14:00:12.310+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SparkContext: Running Spark version 3.4.2
[2025-09-08T14:00:12.336+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO ResourceUtils: ==============================================================
[2025-09-08T14:00:12.336+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-09-08T14:00:12.336+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO ResourceUtils: ==============================================================
[2025-09-08T14:00:12.336+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SparkContext: Submitted application: ECommerce_ETL_Pipeline
[2025-09-08T14:00:12.357+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-09-08T14:00:12.365+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO ResourceProfile: Limiting resource is cpu
[2025-09-08T14:00:12.365+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-09-08T14:00:12.429+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SecurityManager: Changing view acls to: softsuave
[2025-09-08T14:00:12.429+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SecurityManager: Changing modify acls to: softsuave
[2025-09-08T14:00:12.429+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SecurityManager: Changing view acls groups to:
[2025-09-08T14:00:12.430+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SecurityManager: Changing modify acls groups to:
[2025-09-08T14:00:12.430+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: softsuave; groups with view permissions: EMPTY; users with modify permissions: softsuave; groups with modify permissions: EMPTY
[2025-09-08T14:00:12.694+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO Utils: Successfully started service 'sparkDriver' on port 34591.
[2025-09-08T14:00:12.764+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SparkEnv: Registering MapOutputTracker
[2025-09-08T14:00:12.804+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SparkEnv: Registering BlockManagerMaster
[2025-09-08T14:00:12.818+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-09-08T14:00:12.818+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-09-08T14:00:12.854+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-09-08T14:00:12.914+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-31ee92d1-3cc7-480c-8e0f-874399ad2a77
[2025-09-08T14:00:12.988+0530] {subprocess.py:93} INFO - 25/09/08 14:00:12 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
[2025-09-08T14:00:13.002+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-09-08T14:00:13.242+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-09-08T14:00:13.520+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-09-08T14:00:13.552+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO SparkContext: Added JAR file:///media/softsuave/DATA-HDD/DataEngineering/Apache_Airflow/libs/jars/mssql-jdbc-12.2.0.jre8.jar at spark://192.168.6.3:34591/jars/mssql-jdbc-12.2.0.jre8.jar with timestamp 1757320212295
[2025-09-08T14:00:13.694+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO Executor: Starting executor ID driver on host 192.168.6.3
[2025-09-08T14:00:13.698+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-09-08T14:00:13.707+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO Executor: Fetching spark://192.168.6.3:34591/jars/mssql-jdbc-12.2.0.jre8.jar with timestamp 1757320212295
[2025-09-08T14:00:13.744+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO TransportClientFactory: Successfully created connection to /192.168.6.3:34591 after 18 ms (0 ms spent in bootstraps)
[2025-09-08T14:00:13.749+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO Utils: Fetching spark://192.168.6.3:34591/jars/mssql-jdbc-12.2.0.jre8.jar to /tmp/spark-dfe91a5c-ba84-4994-bb34-19d232b1e47e/userFiles-18de8dbe-4700-4e88-a23e-a0fe83d4c846/fetchFileTemp4166107578053482394.tmp
[2025-09-08T14:00:13.890+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO Executor: Adding file:/tmp/spark-dfe91a5c-ba84-4994-bb34-19d232b1e47e/userFiles-18de8dbe-4700-4e88-a23e-a0fe83d4c846/mssql-jdbc-12.2.0.jre8.jar to class loader
[2025-09-08T14:00:13.907+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38685.
[2025-09-08T14:00:13.908+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO NettyBlockTransferService: Server created on 192.168.6.3:38685
[2025-09-08T14:00:13.947+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-09-08T14:00:13.960+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.6.3, 38685, None)
[2025-09-08T14:00:13.975+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.6.3:38685 with 366.3 MiB RAM, BlockManagerId(driver, 192.168.6.3, 38685, None)
[2025-09-08T14:00:13.981+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.6.3, 38685, None)
[2025-09-08T14:00:13.984+0530] {subprocess.py:93} INFO - 25/09/08 14:00:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.6.3, 38685, None)
[2025-09-08T14:00:14.468+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:14,468 - __main__ - INFO - Starting ETL pipeline - Batch ID: 20250908083014
[2025-09-08T14:00:14.468+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:14,468 - __main__ - INFO - Extracting data from table: customers
[2025-09-08T14:00:18.973+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:18,973 - __main__ - INFO - Extracted 1000 records from customers
[2025-09-08T14:00:18.973+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:18,973 - __main__ - INFO - Extracting data from table: products
[2025-09-08T14:00:19.084+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,084 - __main__ - INFO - Extracted 500 records from products
[2025-09-08T14:00:19.085+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,084 - __main__ - INFO - Extracting data from table: orders
[2025-09-08T14:00:19.203+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,203 - __main__ - INFO - Extracted 50000 records from orders
[2025-09-08T14:00:19.204+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,203 - __main__ - INFO - Extracting data from table: order_items
[2025-09-08T14:00:19.304+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,304 - __main__ - INFO - Extracted 86708 records from order_items
[2025-09-08T14:00:19.304+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,304 - __main__ - INFO - Extracting data from table: inventory
[2025-09-08T14:00:19.386+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,386 - __main__ - INFO - Extracted 500 records from inventory
[2025-09-08T14:00:19.387+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,386 - __main__ - INFO - Extracting data from table: clickstream
[2025-09-08T14:00:19.534+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,534 - __main__ - INFO - Extracted 479662 records from clickstream
[2025-09-08T14:00:19.534+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:19,534 - __main__ - INFO - Cleaning customer data...
[2025-09-08T14:00:20.045+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:20,045 - __main__ - INFO - Customer cleaning complete. Records: 1000 -> 1000
[2025-09-08T14:00:20.046+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:20,045 - __main__ - INFO - Cleaning product data...
[2025-09-08T14:00:20.499+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:20,498 - __main__ - INFO - Product cleaning complete. Records: 500 -> 500
[2025-09-08T14:00:20.499+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:20,498 - __main__ - INFO - Cleaning order data...
[2025-09-08T14:00:20.992+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:20,991 - __main__ - INFO - Order cleaning complete. Records: 50000 -> 50000
[2025-09-08T14:00:21.508+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:21,508 - __main__ - INFO - Cleaning order items data...
[2025-09-08T14:00:21.775+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:21,775 - __main__ - INFO - Order items cleaning complete. Records: 86708 -> 86708
[2025-09-08T14:00:22.162+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:22,162 - __main__ - INFO - Cleaning inventory data...
[2025-09-08T14:00:22.342+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:22,342 - __main__ - INFO - Inventory cleaning complete. Records: 500 -> 500
[2025-09-08T14:00:22.514+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:22,514 - __main__ - INFO - Cleaning clickstream data...
[2025-09-08T14:00:26.302+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:26,302 - __main__ - INFO - Clickstream cleaning complete. Records: 479662 -> 479662
[2025-09-08T14:00:28.203+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:28,203 - __main__ - INFO - Creating Customer 360 view...
[2025-09-08T14:00:28.570+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:28,570 - __main__ - INFO - Customer 360 view created with 1000 records
[2025-09-08T14:00:28.570+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:28,570 - __main__ - INFO - Creating Product Analytics view...
[2025-09-08T14:00:28.970+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:28,970 - __main__ - INFO - Product Analytics view created with 500 records
[2025-09-08T14:00:28.970+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:28,970 - __main__ - INFO - Generating data quality report...
[2025-09-08T14:00:29.594+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:29,594 - __main__ - INFO - Loading 1000 records to dim_customers in overwrite mode...
[2025-09-08T14:00:30.959+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:30,959 - __main__ - INFO - Successfully loaded data to dim_customers
[2025-09-08T14:00:31.062+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:31,062 - __main__ - INFO - Loading 500 records to dim_products in overwrite mode...
[2025-09-08T14:00:31.474+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:31,474 - __main__ - INFO - Successfully loaded data to dim_products
[2025-09-08T14:00:31.608+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:31,608 - __main__ - INFO - Loading 50000 records to fact_orders in overwrite mode...
[2025-09-08T14:00:35.357+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:35,357 - __main__ - INFO - Successfully loaded data to fact_orders
[2025-09-08T14:00:35.477+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:35,477 - __main__ - INFO - Loading 86708 records to fact_order_items in overwrite mode...
[2025-09-08T14:00:38.367+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:38,366 - __main__ - INFO - Successfully loaded data to fact_order_items
[2025-09-08T14:00:38.468+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:38,468 - __main__ - INFO - Loading 500 records to dim_inventory in overwrite mode...
[2025-09-08T14:00:38.824+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:38,824 - __main__ - INFO - Successfully loaded data to dim_inventory
[2025-09-08T14:00:41.579+0530] {subprocess.py:93} INFO - 2025-09-08 14:00:41,579 - __main__ - INFO - Loading 479662 records to fact_clickstream in overwrite mode...
[2025-09-08T14:01:10.607+0530] {subprocess.py:93} INFO - 2025-09-08 14:01:10,606 - __main__ - INFO - Successfully loaded data to fact_clickstream
[2025-09-08T14:01:11.041+0530] {subprocess.py:93} INFO - 2025-09-08 14:01:10,766 - __main__ - INFO - Loading 1000 records to analytics_customer_360 in overwrite mode...
[2025-09-08T14:01:11.118+0530] {subprocess.py:93} INFO - 25/09/08 14:01:11 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2025-09-08T14:01:22.204+0530] {subprocess.py:93} INFO - 2025-09-08 14:01:22,189 - __main__ - INFO - Successfully loaded data to analytics_customer_360
[2025-09-08T14:01:22.389+0530] {subprocess.py:93} INFO - 2025-09-08 14:01:22,343 - __main__ - INFO - Loading 500 records to analytics_product_performance in overwrite mode...
[2025-09-08T14:01:23.318+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.322+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.329+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.417+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.419+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.499+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.501+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.565+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.566+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.605+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.606+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.767+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.769+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.927+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.928+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.981+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:23.982+0530] {subprocess.py:93} INFO - 25/09/08 14:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:26.129+0530] {subprocess.py:93} INFO - 25/09/08 14:01:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:26.130+0530] {subprocess.py:93} INFO - 25/09/08 14:01:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:26.834+0530] {subprocess.py:93} INFO - 25/09/08 14:01:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:26.835+0530] {subprocess.py:93} INFO - 25/09/08 14:01:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:27.012+0530] {subprocess.py:93} INFO - 25/09/08 14:01:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:27.012+0530] {subprocess.py:93} INFO - 25/09/08 14:01:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:27.053+0530] {subprocess.py:93} INFO - 25/09/08 14:01:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:27.054+0530] {subprocess.py:93} INFO - 25/09/08 14:01:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:27.103+0530] {subprocess.py:93} INFO - 25/09/08 14:01:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:27.103+0530] {subprocess.py:93} INFO - 25/09/08 14:01:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.
[2025-09-08T14:01:27.510+0530] {subprocess.py:93} INFO - 2025-09-08 14:01:27,509 - __main__ - INFO - Successfully loaded data to analytics_product_performance
[2025-09-08T14:03:32.902+0530] {subprocess.py:93} INFO - 25/09/08 14:03:32 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 121743 ms exceeds timeout 120000 ms
[2025-09-08T14:03:35.342+0530] {subprocess.py:93} INFO - 25/09/08 14:03:35 WARN SparkContext: Killing executors is not supported by current scheduler.
[2025-09-08T14:03:37.675+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.676+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.676+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.676+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.676+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.676+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.677+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.677+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.677+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.677+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.677+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.677+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.678+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.678+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.678+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.679+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.679+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.679+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.680+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.680+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.680+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.680+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.680+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.680+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.681+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.681+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.682+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.682+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.682+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.682+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.682+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.682+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.683+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.683+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.683+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.683+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.683+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.683+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.684+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.684+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.684+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.684+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.684+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.684+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.685+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.685+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.685+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.685+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.685+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.686+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.687+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.688+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.689+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.689+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.689+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.689+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.689+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.689+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.689+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.689+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.690+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.690+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.690+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.690+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.690+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.690+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.690+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.690+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.691+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.692+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.693+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.694+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.695+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.696+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.697+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.698+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.699+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.700+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.701+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.702+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.703+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.704+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.705+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.706+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.707+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.708+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.709+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.710+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.711+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.712+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.713+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.714+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.715+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.716+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.717+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.718+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.719+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.720+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.721+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.722+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.723+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.724+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.725+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.726+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.727+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.728+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.729+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.730+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.731+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.732+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.733+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.734+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.735+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.736+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.737+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.738+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.739+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.740+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.741+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.742+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.743+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.744+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.745+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.746+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.747+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.748+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.749+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.750+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.751+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.752+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.753+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.754+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.755+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.756+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.757+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.758+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.759+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.760+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.761+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.762+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.763+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.764+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.765+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.766+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.767+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.768+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 25/09/08 14:03:37 ERROR Inbox: Ignoring error
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:37.769+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.770+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:37.771+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:37.772+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:39.882+0530] {subprocess.py:93} INFO - 25/09/08 14:03:39 WARN Executor: Issue communicating with driver in heartbeater
[2025-09-08T14:03:39.883+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:39.883+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:39.884+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:39.884+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)
[2025-09-08T14:03:39.884+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)
[2025-09-08T14:03:39.884+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)
[2025-09-08T14:03:39.884+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)
[2025-09-08T14:03:39.884+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)
[2025-09-08T14:03:39.885+0530] {subprocess.py:93} INFO - 	at org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)
[2025-09-08T14:03:39.885+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:39.885+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)
[2025-09-08T14:03:39.885+0530] {subprocess.py:93} INFO - 	at org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)
[2025-09-08T14:03:39.885+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
[2025-09-08T14:03:39.885+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
[2025-09-08T14:03:39.886+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
[2025-09-08T14:03:39.886+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
[2025-09-08T14:03:39.886+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:39.886+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:39.886+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:39.886+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:39.887+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:39.887+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:39.887+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:39.887+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:39.887+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:39.887+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:39.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:39.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:39.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:39.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:39.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:39.888+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:39.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:39.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:39.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:39.889+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:39.889+0530] {subprocess.py:93} INFO - 	... 3 more
[2025-09-08T14:03:39.889+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:39.890+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:39.890+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:39.890+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:39.890+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:39.890+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:39.890+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:39.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:39.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:39.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:39.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:39.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:39.891+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:39.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:39.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:39.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:39.892+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:39.892+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:39.893+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:39.893+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:39.893+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:39.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:39.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:39.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:39.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:39.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:39.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:39.894+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:39.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:39.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:39.895+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:39.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:39.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:39.895+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:39.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:39.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:39.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:39.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:39.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:39.896+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:39.897+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:39.897+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:39.897+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:39.897+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:39.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:39.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:39.897+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:39.897+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:39.898+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:39.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:39.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:39.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:39.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:39.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:39.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:39.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:39.898+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:39.899+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:39.899+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:39.899+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:39.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:39.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:39.899+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:39.899+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:39.899+0530] {subprocess.py:93} INFO - 25/09/08 14:03:39 ERROR Inbox: Ignoring error
[2025-09-08T14:03:39.899+0530] {subprocess.py:93} INFO - org.apache.spark.SparkException: Exception thrown in awaitResult:
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)
[2025-09-08T14:03:39.900+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at java.lang.Thread.run(Thread.java:750)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.6.3:34591
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)
[2025-09-08T14:03:39.901+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:39.902+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
[2025-09-08T14:03:39.903+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess(Promise.scala:94)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.trySuccess$(Promise.scala:94)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
[2025-09-08T14:03:39.904+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete(Promise.scala:53)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.complete$(Promise.scala:52)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success(Promise.scala:86)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	at scala.concurrent.Promise.success$(Promise.scala:86)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	at org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)
[2025-09-08T14:03:39.905+0530] {subprocess.py:93} INFO - 	... 8 more
[2025-09-08T14:03:40.676+0530] {subprocess.py:93} INFO - 2025-09-08 14:03:40,631 - __main__ - INFO - Loading 18 records to etl_data_quality_log in append mode...
[2025-09-08T14:03:47.807+0530] {subprocess.py:93} INFO - 2025-09-08 14:03:47,806 - __main__ - INFO - Successfully loaded data to etl_data_quality_log
[2025-09-08T14:03:47.807+0530] {subprocess.py:93} INFO - 2025-09-08 14:03:47,807 - __main__ - INFO - ETL pipeline completed successfully - Batch ID: 20250908083014
[2025-09-08T14:03:47.807+0530] {subprocess.py:93} INFO - 
[2025-09-08T14:03:47.807+0530] {subprocess.py:93} INFO - ============================================================
[2025-09-08T14:03:47.807+0530] {subprocess.py:93} INFO - ETL Pipeline Summary - Batch ID: 20250908083014
[2025-09-08T14:03:47.807+0530] {subprocess.py:93} INFO - ============================================================
[2025-09-08T14:03:47.807+0530] {subprocess.py:93} INFO - 
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO - CUSTOMERS:
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO -   initial_count: 1000
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO -   final_count: 1000
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO -   duplicates_removed: 0
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO - 
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO - PRODUCTS:
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO -   initial_count: 500
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO -   final_count: 500
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO -   invalid_prices_removed: 0
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO - 
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO - ORDERS:
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO -   initial_count: 50000
[2025-09-08T14:03:47.808+0530] {subprocess.py:93} INFO -   final_count: 50000
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO -   amount_mismatches: 0
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO - 
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO - ORDER_ITEMS:
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO -   initial_count: 86708
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO -   final_count: 86708
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO -   line_total_mismatches: 0
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO - 
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO - INVENTORY:
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO -   initial_count: 500
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO -   final_count: 500
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO -   out_of_stock_count: 132
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO - 
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO - CLICKSTREAM:
[2025-09-08T14:03:47.809+0530] {subprocess.py:93} INFO -   initial_count: 479662
[2025-09-08T14:03:47.810+0530] {subprocess.py:93} INFO -   final_count: 479662
[2025-09-08T14:03:47.810+0530] {subprocess.py:93} INFO -   potential_bots: 0
[2025-09-08T14:03:47.810+0530] {subprocess.py:93} INFO - ============================================================
[2025-09-08T14:03:47.810+0530] {subprocess.py:93} INFO - 
[2025-09-08T14:03:52.810+0530] {subprocess.py:93} INFO - 2025-09-08 14:03:52,810 - py4j.clientserver - INFO - Closing down clientserver connection
[2025-09-08T14:03:56.936+0530] {subprocess.py:93} INFO - [2025-09-08 14:03:56] âœ… ETL Pipeline completed successfully!
[2025-09-08T14:03:56.939+0530] {subprocess.py:93} INFO - [2025-09-08 14:03:56] ðŸŽ‰ Data loaded into target DB: ecom_dwh
[2025-09-08T14:03:56.941+0530] {subprocess.py:97} INFO - Command exited with return code 0
[2025-09-08T14:03:57.154+0530] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-09-08T14:03:57.506+0530] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecom_etl_10min, task_id=run_etl_pipeline, run_id=scheduled__2025-09-08T08:20:00+00:00, execution_date=20250908T082000, start_date=20250908T083003, end_date=20250908T083357
[2025-09-08T14:03:58.342+0530] {local_task_job_runner.py:243} INFO - Task exited with return code 0
[2025-09-08T14:03:58.358+0530] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-09-08T14:03:58.358+0530] {local_task_job_runner.py:222} INFO - ::endgroup::
